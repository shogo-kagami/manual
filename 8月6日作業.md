
### 作業内容ここから ###
L3ルームに入室し、白河DGX ログインノードに user21020 でSSHログイン  
```
X6{nb[#{7IJY4B
```
以下を実行（指定したノードの slurm job を停止）  
```
scancel -w srdgx00002,srdgx00005
```
```
squeue -p 021-partition --me
```
を実行し、cronjobにより5分程度で停止したnodeのslurm jobが復活することを確認
 USERSTがCGからRになれば上がっている状態である。
　JOBIDは起動順になっている。

背景
既知の問題として、何らかの理由でslurm job内部のLLM推論プロセスが再起動すると、GPUメモリが開放されずに残ってしまうことがわかっています
vllm 起因のバグで、対応は現在検討中
https://ray-dashboard.sbintuitions.com/#/cluster を観察すると、現在上記で列挙したノードでGPUメモリが開放されずに残っているようです
これらのノード上では推論プロセスが稼働していない状態で、停止しても影響はない
応急処置として slurm job を再起動すると問題が解消するので、その対応をお願いしたいです
恒久対応は 1) メモリが解放されないバグの修正, 2) 異常検知と自動scancelの実装（1が困難な場合）, です。まず 1 を検討中です
