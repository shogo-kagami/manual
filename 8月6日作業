
### 作業内容ここから ###
L3ルームに入室し、白河DGX ログインノードに user21020 でSSHログイン
X6{nb[#{7IJY4B

以下を実行（指定したノードの slurm job を停止）
scancel -w srdgx00010,srdgx00021,srdgx00012
squeue -p 021-partition
を実行し、cronjobにより5分程度で停止したnodeのslurm jobが復活することを確認
USERSTがCGからRになれば上がっている状態である。
JOBIDは起動順になっている。

背景
既知の問題として、何らかの理由でslurm job内部のLLM推論プロセスが再起動すると、GPUメモリが開放されずに残ってしまうことがわかっています
vllm 起因のバグで、対応は現在検討中
https://ray-dashboard.sbintuitions.com/#/cluster を観察すると、現在上記で列挙したノードでGPUメモリが開放されずに残っているようです
これらのノード上では推論プロセスが稼働していない状態で、停止しても影響はない
応急処置として slurm job を再起動すると問題が解消するので、その対応をお願いしたいです
恒久対応は 1) メモリが解放されないバグの修正, 2) 異常検知と自動scancelの実装（1が困難な場合）, です。まず 1 を検討中です
